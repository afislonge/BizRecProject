# -*- coding: utf-8 -*-
"""Recommendation_Model_HT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dPJklD5Qa3Q0sQt1zKe2rInpz5p1YxqE
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
from surprise import Dataset, Reader, SVD, KNNBasic, KNNWithMeans, NMF, BaselineOnly
from surprise.model_selection import train_test_split, cross_validate
from textblob import TextBlob
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re
from sklearn.metrics import mean_squared_error
import optuna
from datetime import datetime
from collections import defaultdict

# Download required NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

class HybridRecommender:
    def __init__(self):
        self.business_df = None
        self.user_df = None
        self.reviews_df = None
        self.checkin_df = None
        self.tfidf_matrix = None
        self.cosine_sim = None
        self.best_model = None
        self.sentiment_scores = None
        self.checkin_scores = None
        self.popular_items = None
        self.user_profiles = {}

    def load_and_preprocess_data(self, business_path, user_path, reviews_path, checkin_path):
        """
        Load and preprocess all datasets
        """
        # Load data
        self.business_df = pd.read_csv(business_path)
        self.user_df = pd.read_csv(user_path)
        self.reviews_df = pd.read_csv(reviews_path)
        self.checkin_df = pd.read_csv(checkin_path)

        # Preprocess data
        self.preprocess_business_data()
        self.preprocess_user_data()
        self.calculate_sentiment_scores()
        self.calculate_checkin_scores()
        self.calculate_popular_items()
        self.create_user_profiles()

    def preprocess_business_data(self):
        """
        Preprocess business data
        """
        # Clean categories
        self.business_df['processed_categories'] = self.business_df['categories'].apply(self.preprocess_text)

        # Calculate average ratings
        business_avg_ratings = self.reviews_df.groupby('business_id')['stars'].agg(['mean', 'count']).reset_index()
        self.business_df = self.business_df.merge(business_avg_ratings, on='business_id', how='left')

        # Create business features
        self.business_df['price_level'] = pd.to_numeric(self.business_df['attributes'].apply(
            lambda x: str(x).count('$') if pd.notnull(x) else 0
        ))

    def preprocess_user_data(self):
        """
        Preprocess user data
        """
        # Calculate user activity metrics
        user_activity = self.reviews_df.groupby('user_id').agg({
            'business_id': 'count',
            'stars': 'mean'
        }).reset_index()
        user_activity.columns = ['user_id', 'review_count', 'average_rating']

        self.user_df = self.user_df.merge(user_activity, on='user_id', how='left')

    def create_user_profiles(self):
        """
        Create user profiles based on their review history
        """
        for user_id in self.user_df['user_id'].unique():
            user_reviews = self.reviews_df[self.reviews_df['user_id'] == user_id]

            if len(user_reviews) > 0:
                # Get businesses reviewed by user
                reviewed_businesses = self.business_df[
                    self.business_df['business_id'].isin(user_reviews['business_id'])
                ]

                # Calculate category preferences
                category_preferences = defaultdict(float)
                for _, business in reviewed_businesses.iterrows():
                    categories = str(business['categories']).split(', ')
                    rating = user_reviews[
                        user_reviews['business_id'] == business['business_id']
                    ]['stars'].iloc[0]

                    for category in categories:
                        category_preferences[category] += rating

                # Normalize category preferences
                total_ratings = sum(category_preferences.values())
                if total_ratings > 0:
                    category_preferences = {
                        k: v/total_ratings for k, v in category_preferences.items()
                    }

                self.user_profiles[user_id] = {
                    'category_preferences': category_preferences,
                    'avg_rating': user_reviews['stars'].mean(),
                    'review_count': len(user_reviews)
                }

    def calculate_popular_items(self):
        """
        Calculate popular items for cold start recommendations """
        # Combine review ratings, sentiment scores, and check-in data
        business_metrics = pd.DataFrame()
        business_metrics['business_id'] = self.business_df['business_id']
        business_metrics['avg_rating'] = self.business_df['mean']
        business_metrics['review_count'] = self.business_df['count']

        # Merge sentiment scores
        business_metrics = business_metrics.merge(
            self.sentiment_scores, on='business_id', how='left'
        )

        # Merge check-in scores
        business_metrics = business_metrics.merge(
            self.checkin_scores, on='business_id', how='left'
        )

        # Calculate popularity score
        business_metrics['popularity_score'] = (
            business_metrics['avg_rating'] * 0.4 +
            business_metrics['review_count'] * 0.3 +
            business_metrics['sentiment_score'] * 0.2 +
            business_metrics['checkin_score'] * 0.1
        )

        self.popular_items = business_metrics.sort_values(
            'popularity_score', ascending=False
        )

    def evaluate_recommendations(self, user_id, recommended_items, k=10):
        """
        Evaluate recommendations using Recall@K, Precision@K, NDCG, and Diversity Score
        """
        # Get actual items rated by the user
        actual_items = set(self.reviews_df[self.reviews_df['user_id'] == user_id]['business_id'])

        # Calculate Precision@K
        recommended_set = set(recommended_items[:k])
        precision = len(recommended_set.intersection(actual_items)) / k

        # Calculate Recall@K
        recall = len(recommended_set.intersection(actual_items)) / len(actual_items) if actual_items else 0

        # Calculate NDCG
        ndcg = self.calculate_ndcg(recommended_items, actual_items, k)

        # Calculate Diversity Score
        diversity = self.calculate_diversity(recommended_items)

        return {
            'Precision@K': precision,
            'Recall@K': recall,
            'NDCG': ndcg,
            'Diversity Score': diversity
        }

    def calculate_ndcg(self, recommended_items, actual_items, k):
        """
        Calculate NDCG for the top K recommendations
        """
        dcg = 0
        for i, item in enumerate(recommended_items[:k]):
            if item in actual_items:
                dcg += 1 / np.log2(i + 2)  # +2 because index starts at 0

        idcg = sum(1 / np.log2(i + 2) for i in range(min(k, len(actual_items))))

        return dcg / idcg if idcg > 0 else 0

    def calculate_diversity(self, recommended_items):
        """
        Calculate diversity score based on the number of unique categories in the recommended items
        """
        unique_categories = set()
        for item in recommended_items:
            categories = self.business_df[self.business_df['business_id'] == item]['categories'].values
            if categories:
                unique_categories.update(categories[0].split(', '))

        return len(unique_categories) / len(recommended_items) if recommended_items else 0

    def preprocess_text(self, text):
        """
        Preprocess text data
        """
        if isinstance(text, str):
            # Convert to lowercase
            text = text.lower()
            # Remove special characters and digits
            text = re.sub(r'[^a-zA-Z\s]', '', text)
            # Tokenization
            tokens = word_tokenize(text)
            # Remove stopwords and lemmatize
            stop_words = set(stopwords.words('english'))
            lemmatizer = WordNetLemmatizer()
            tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
            return ' '.join(tokens)
        return ''

# Example usage
recommender = HybridRecommender()
recommender.load_and_preprocess_data('business.csv', 'user.csv', 'reviews.csv', 'checkin.csv')
best_model, model_results = recommender.find_best_collaborative_model()
print(f"Best Collaborative Model: {best_model}, Results: {model_results}")

# Example evaluation
user_id = 1  # Replace with a valid user ID
recommended_items = recommender.popular_items['business_id'].head(10).tolist()  # Get top 10 recommended items
evaluation_results = recommender.evaluate_recommendations(user_id, recommended_items)
print(f"Evaluation Results: {evaluation_results}")